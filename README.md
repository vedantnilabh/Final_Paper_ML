# Final_Paper_ML

## About
This is the Github repo for the code associated with the final project for our Neural Networks Class (CS 8321) which is a reaserch paper. 

The paper specifically is an explority study about potential circuits that could be found in Stable Diffusion models. 
To find these circuits we ran a gradient decent of the each of the filters of the Stable Diffusion model to identify
the minimally excitrory image and to visually analyze them.

## Motivation 
In recent years, there has been a noticeable surge in interest, both within academic circles and among the general public, surrounding Generative AI. This surge began with the publication of Generative Adversarial Networks (GANs) [1], which quickly became a preeminent research topic in the deep learning space, leading to rapid advancements in performance of GANs. However, with the publication of DDPM, diffusion models quickly supplanted GANs as state of the art in image generation. However, these models, while achieving state of the art results, tend to be computationally expensive to train due to their use of a denoising auxiliary task to train, which is done in steps. Stable Diffusion attempted to combat this issue by performing the diffusion process directly in a pre-trained latent space, which stabilizes training, decreases training computation, and achieves even better results, Latent Diffusion Models quickly have become the state-of-the-art family of generative models, and have led to more hype and attention in the Generative AI space than ever before. 
	However, because this is such a novel approach, there hasn’t been much investigation into the inner workings of the model. From an interpretability perspective, this is problematic, because of how much attention Stable Diffusion has garnered, and how many non-technical people are using it, from artists to graphic designers. 
	We are interested in conducting a preliminary investigation into the inner workings of the trained Stable Diffusion Model. This primarily comes in the form of the U-Net, which is the backbone of the model. Because this is a convolutional neural network (CNN), an enduring model type which has been the subject of much interpretability research, we want to explore whether applying existing interpretability techniques for this broad family models on the Stable Diffusion U-Net can allow us to glean some insight into what the model is doing inside the latent space during the diffusion process. 
	However, there is one important caveat: the overwhelming majority of research in interpretability for CNNs is focused on Classification Networks often trained on ImageNet, for instance, and that makes some of the often-employed ideas and techniques either not useful or in need of modification to fit our constraints, as the U-Net, is not a classification network, but a fully convolutional network. As a result, some of the common intuitions and motivations used to analyze traditional Classification Networks may not hold.
	Thus, another point of our investigation is whether using these techniques will even produce anything meaningful for our purposes, or if they can be reworked to do so. 
## Related Work
To elaborate, stable diffusion is composed of three components, a pre-trained autoencoder, a U-net, and some encoder (commonly CLIP) to incorporate context in the diffusion process. The U-net is a fully convolutional network that is trained to denoise an image. This differs from traditional CNNs which are trained to classify images. The way this works is an image is encoded in the latent space using the encoder inside the autoencoder, and then noise is added to that latent representation of the image. This is then passed through the U-net which outputs a noise prediction of the latent representation which is then removed from the previous representation. This process is then repeated a number of times (typically 1000) until the latent representation is denoised and then that is passed through the decoder to get an output image. Once this is trained, the model becomes capable of generating new images from noise given some added context via some encoder through cross-attention. 
	Interoperability is a well-researched topic in the CNN space. One popular technique for visualizing individual filters in a trained CNN model is finding maximally exciting images by using gradient ascent in the input space. This technique is powerful because the generated image gives intuition as to what a given filter is actually doing in the network. This was combined with filter weight analysis to assess strong connections between layers by OpenAI. This technique was referred to by them as circuits and provides strong evidence for the information distillation pipeline. This is a common intuition for CNNs, where early layers learn generalizable features like basics textures and edge detection which turns into more complex processes like curve detection leading to further complex filters in later layers useful for the final classification, such as a face detector.  However, there is no guarantee that this assumption will hold in the stable diffusion U-net because it is fundamentally performing a different task (noise prediction vs classification) and because the U-net uses an encoder/decoder architecture that has concatenations between earlier and later layers of the same spatial resolution to add earlier context to the later layers.  This could mean that the U-net is doing a combination of abstract processing as described by the information distillation pipeline and contextualizing from early layers where there are less abstract representations.
	In terms of directly relating works that try to understand the inner workings of stable diffusion, there was a recent paper that focused on using cross-attention word pixel scores in the U-net to produce attribution maps which were used by the researchers to better understand the U-net ‘s cross attention mechanism in the context of clip from a  “visuolinguistic“ perspective.   This was the only paper that we could find on stable diffusion interpretability. 
	Our focus in this paper is not on the cross-attention mechanism, but rather on the filters themselves by using techniques mentioned earlier to help illuminate the black box that stable diffusion currently is.

## Methods 
In order to visualize filters, we will be using a variant of maximal excitation, which was done by Open AI as a part of their microscope project. However, we will be tweaking our approach to better suit the U-net’s noise prediction task: by performing gradient descent in the latent space, as opposed to the gradient ascent approach usually done. This is because this be belter mimics the diffusion process, which also involves successively taking some latent noise, making a noise prediction, and iteratively subtracting that noise from the latent tensor over some predetermined n steps, and then putting the “denoised” latent tensor into the decoder for the final output image.  The only difference between the standard stable diffusion process and our approach is we aren’t subtracting a predicted noise tensor, we are subtracting a gradient associated with the mean of the output activations of a particular multichannel filter in the diffusion U-net, and successively doing that over n steps.
Equation 1 - Gradient Descent in the Latent Space
I ← I - η∇f_c (I)
	In the equation, I represents the latent encoding of the maximally inhibitory image, c is the output neuron and f is the diffusion model and eta is the learning rate. Additionally, the gradient is computed on the mean of the output neuron with respect to I. After some number of steps n, we put I through the decoder to get the output image. 
	We initialize our diffusion model to take a text length of 0 for the clip embedding (meaning the cross-attention layers become all pass), and perform the timestep embedding in the same way as done in the official Keras implementation. Our gradients are calculated by using tf.gradient_tape, which can compute these gradients automatically via the computation graph.
	Lastly, when determining the number of steps n, we initially tested n = 1000, which was the number of steps used during training, but we also tested n=50, 100 and 300, and qualitatively found that the results had converged to a minimum at 300. We also tested eta of 0.1, 1 and 5, and found the combination of eta=5, and n=300, to give the best tradeoff between image quality and computation time. 
	In order to generate a circuit, we took the maximal norms (L2) of the single channel filters within the output convolutional layer (composed of 4 multi-channel filters). We then recursively found the maximal norms of the single channel filters within the multi-channel filter corresponding to the previous single-channel filter. We then did this for all the convolutional layers in the U-Net. We were not able to visualize all the layers because the model that we used had custom defined ResBlock layers that contained 2 convolutional layers, so even though we could access the weights, we couldn’t isolate the output of a particular layer in the block, meaning we could only visualize the second convolutional layer in the block. However, we could still access the weights, so we could still find the norms and derived our circuits following the above procedure. We then repeated this process five times to find five important circuits within the network.
	We then took these visualizations and matched them with the single channel filter in the previous multichannel filter that corresponded to them to understand the connections between them. This is the idea of using circuits, that the connections in a CNN can be used to understand how filters are progressively aggregated in the network to form filters later in the network. If these weights are positive, we would say that the relationship between two filters is excitatory, and if they are negative, we would say this relationship in inhibitory. However, because we couldn’t visualize the intermediary filters inside the ResBlock (only can visualize output), we had to account for this by performing a matrix multiplication for the single channel filters between the multichannel filters we could visualize to account for this effect. We do this in the order that they occur sequentially in the network, as this mimics the feedforward process used in inference and thus is a more accurate way to gauge the aggregate effect of one multichannel filter on another multichannel filter The idea was that using matrix multiplication will give us a proxy for how the two nonadjacent layers interact with each other, making it so that excitatory times excitatory will give us excitatory, as will inhibitory times inhibitory, but excitatory times inhibitory (or vice versa) will give us inhibitory. While this method isn’t perfect, it is useful enough as a proxy, and will still serve as a useful tool to understand the diffusion model in the context of circuits.  
	Beyond Circuits, we also wanted to understand the role of concatenations in the U-Net in terms of how it can take less processed features early in the network and use them as it is decoding to the output noise prediction, such that it learns to combine processing and earlier context via these concatenations. We did this by following the methodology from the Branch Specialization Article in the Open AI Circuits thread,  We essentially can understand what a particular layer is doing and how it connects to a connecting layer by performing a singular value decomposition on the matrix multiplication of the weight matrices, such that this matrix multiplication is of size weights in the previous layer times weights in the next layer, where the matrices are multiplied on the common filter and channel number they share, because the number of filters in the previous layer determines the number of channels in the next layer. This is adjusted based on concatenations if we grab the first n channels in the connecting layer or the last n channels. We can then perform the singular value decomposition as follows: 
 
W=UΣV^T  
	Where W is the result of the matrix multiplication between the connecting layers of size mxn, U is the left Singular Matrix containing the eigenvectors of WWT of size mxm, Σ is the Diagonal Matrix of the Singular Values of size mxn and V is the right singular matrix containing the eigenvectors of WT W of size nxn. Because of the way we multiplied, m is the number of weights per filter in the first layer, and n is the number of weights per channel in the connecting layer. We then project the weights of the first layer onto the left singular vectors U, by multiplying the weights in the initial layer by the first 2 singular vectors, and project the weights of the connecting layers onto the right eigenvectors by multiplying the weights by the first 2 right singular vectors. These are the sets of singular vectors corresponding to the two highest singular values and gives us two points on the left singular vectors for every filter in the initial layer and two points on the right singular vectors for every channel in the connecting layer. However, all the layers we visualized had the same number of filters between connecting layers, meaning we can interpret the results validly as showing how the filters in the initial layer connect to some directly connecting layer, and how the filters in the connecting layer connect to the initial layer based on their respective values on the projected singular vector spaces. This is useful because we can use this to determine what a layer is doing in aggregate based on the singular vectors and how the connecting layers relate. We used this to visualize the concatenating layers on those channels such that we visualize each filter on the corresponding singular vectors to see how they connect to the other layer in the visualization. We felt this would allow us to better understand how the U-net incorporates earlier context when it is decoding to get the final noise prediction for each step in the diffusion process and see how that differs from the information distillation pipeline observed in standard CNN’s.

## Results
The minimally excitatory images become more abstract in the middle of the network and then simpler towards the beginning and end of the network. For example, from one of the circuits that we visualized (Appendix A) we see that filter 218 in layer 6 (first convolutional layer in the network), when visualized, is just a single color with little to no pattern. But as we get deeper into the network, around layer 12, simple patters appear, often in a grid-like structure. If we then visualize filters near the middle of the network, we see very abstract filters, as we do with layer 21 filter 251. However, as we decode out of the middle part of the U-net, this trend reverses and the visualizations become simpler. Layer 48 filter 116 once again takes on a grid-like structure. Near the very end of the network, we see very simple filters with minimal pattern complexity. We hypothesize that this behavior is evidence of the information distillation pipeline as in a traditional CNN in the first half of the network, and then using prior context from the concatenations in tandem with what it has learned about the image in its own latent representation to decode to the original autoencoder latent space in order to make the noise prediction needed for the diffusion process.  
	After the initial layers, we see very high frequency patterns emerge. For example, in layer 12 filter 354 has the pattern repeating about 30 times in each row with that coming down to 8 in the 21st layer near the middle of the network. The pattern frequency then goes back to around 16 in the 48th layer near the end of the network. We hypothesize that the changes in pattern frequency is a result of increased abstraction happening near the middle of the network where the high-frequency patterns are not useful to the middle of the network because it takes the previously learned information on image features and tries to put that in a meaningful encoding that it can then decode out of.
	We also observed some evidence of the circuit phenomenon as described by OpenAI. Specifically, in Appendix B we see two filter visualizations that are connected by the 3x3 weights shown. In the first pair of images, we see that the filter is highly excitatory (all the weights are positive), we hypothesize that this is a contributing factor as to why the visualizations of the two filters are similar. For the second set of visualizations, the filter is mostly excitatory with the top row being strongly positive and the rest being near zero. There is still a strong resemblance between the two filters, but they have differing characteristics, which we believe is because filter is not as excitatory. Lastly, we see two filters connected by a highly inhibitory kernel, where all the weights are strongly negative. The visualizations of the two connected filters are very different, there is hardly any similarity in the patterns generated.
	 The scatter plots shown are generated by the previously described process for Branch Specialization in the methodology, and show layers 9 and 38 in the network, which are a concatenation, and how each filter connects to the filters in its connecting layer. We visualized some of these filters to understand what the concatenation is doing in the context of the model and found that the singular vectors in layer 9 seem to correspond to texture and color respectively.  In layer 38, we were felt that singular vector 1 was color, but were less sure about singular vector 0 (texture?). Furthermore, we also saw that the filters that were further away from other filters in 38 were less similar to the filters in layer 6, as that means they connected differently to the filters in layer 6 and are different from the other filters in layer 38. 
  
 
One limitation of our analysis includes not considering the effect of residual connections within the U-net. This is difficult to analyze but OpenAi has shown that residual networks can also be understood through the idea of parallel branches existing throughout the network. Secondly, we also ignored the cross-attention layers between convolutional layers in the U-net which gives us an incomplete understanding because of how important these layers are to the model’s ability to generate conditionally. Lastly, because we used the Keras implementation of Stable Diffusion, we were unable to access the outputs of the first convolutional layer in each residual block making our circuit analysis somewhat incomplete.

##Conclusion
	We found that existing CNN interpretation techniques work when analyzing the Stable Diffusion U-net. Though our analysis did not consider every characteristic of the model we still found evidence for circuits, the information distillation pipeline and arrived at a reasonable intuition for what the Diffusion model is doing.
  
##References

[1] 	I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in Proc. Advances Neural Information Processing Systems Conf., 2014, pp. 2672–2680.





