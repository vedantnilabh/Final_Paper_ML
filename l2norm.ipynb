{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 22:03:15.296860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 22:03:17.561522: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.7.0-vbhdtgc7dl4kpo4auyswsh6w3udcnf5x/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/neovim-0.7.0-terkir3wk5rst6ktv4uxyaqjditacv5p/lib\n",
      "2023-04-27 22:03:17.561657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cudnn-8.2.4.15-11.4-eluwegpwn6adr7hlku5p5wru5xzefpop/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/cuda-11.7.0-vbhdtgc7dl4kpo4auyswsh6w3udcnf5x/lib64:/hpc/mp/spack/opt/spack/linux-ubuntu20.04-zen2/gcc-10.3.0/neovim-0.7.0-terkir3wk5rst6ktv4uxyaqjditacv5p/lib\n",
      "2023-04-27 22:03:17.561671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "You do not have pycocotools installed, so KerasCV pycoco metrics are not available. Please run `pip install pycocotools`.\n",
      "You do not have pyococotools installed, so the `PyCOCOCallback` API is not available.\n",
      "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/skoka/.venv/MLEnv3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_cv\n",
    "from keras_cv.models import StableDiffusion\n",
    "from keras_cv.models.stable_diffusion.diffusion_model import DiffusionModel\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "\n",
    "\n",
    "SAVE_PATH = \"/users/skoka/Documents/Final_Paper_ML\"\n",
    "\n",
    "\n",
    "Stable_diffusion = StableDiffusion(img_height=512, img_width=512)\n",
    "decoder = Stable_diffusion.decoder\n",
    "\n",
    "diffusion_model = DiffusionModel(img_width = 512, img_height = 512, max_text_length=0)\n",
    "\n",
    "import math\n",
    "def get_timestep_embedding(timestep, batch_size, dim=320, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = tf.math.exp(\n",
    "            -math.log(max_period) * tf.range(0, half, dtype=tf.float32) / half\n",
    "        )\n",
    "        args = tf.convert_to_tensor([timestep], dtype=tf.float32) * freqs\n",
    "        embedding = tf.concat([tf.math.cos(args), tf.math.sin(args)], 0)\n",
    "        embedding = tf.reshape(embedding, [1, -1])\n",
    "        return tf.repeat(embedding, batch_size, axis=0)\n",
    "\n",
    "# we are going to need to modify this code a lot \n",
    "def generate_pattern(layer_name, filter_index, size=64):\n",
    "    # Build a model that outputs the activation\n",
    "    # of the nth filter of the layer considered.\n",
    "    layer_output = diffusion_model.get_layer(layer_name).output\n",
    "    # Isolate the output \n",
    "    new_model = tf.keras.models.Model(inputs=diffusion_model.inputs, outputs=layer_output)\n",
    "    \n",
    "    # We start from a gray image with some uniform noise\n",
    "    input_img_data = np.random.random((1, size, size, 4)) * 20 + 128.\n",
    "    I = tf.Variable(input_img_data, name='image_var', dtype = 'float64')\n",
    "    #I = preprocess_input(I_start) # only process once\n",
    "    # Run gradient ascent for 40 steps\n",
    "    eta = 5\n",
    "    for i in range(100):\n",
    "        start = time.time()\n",
    "        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "            time_embedding = get_timestep_embedding(i, 1)\n",
    "            # create a tensor with the following size of all zeros: (None, 0, 768)\n",
    "            word_embedding = tf.zeros((1, 0, 768))\n",
    "            tape.watch(I)\n",
    "            # get variable to maximize\n",
    "            model_vals = new_model((I, time_embedding, word_embedding))\n",
    "            loss = tf.reduce_mean(model_vals[:, :, :, filter_index])\n",
    "\n",
    "        # Compute the gradient of the input picture w.r.t. this loss\n",
    "        # add this operation input to maximize\n",
    "        grad_fn = tape.gradient(loss, I)\n",
    "        # Normalization trick: we normalize the gradient\n",
    "        grad_fn /= (tf.sqrt(tf.reduce_mean(tf.square(grad_fn))) + 1e-5) # mean L2 norm\n",
    "        I = I + (grad_fn * eta) # one iteration of maximizing\n",
    "        end = time.time()\n",
    "        print(\"Iteration: {}, Loss: {}, Time: {}\".format(i, loss, end-start))\n",
    "    # decode the resulting input image\n",
    "    I = decoder(I)\n",
    "    # return the numpy matrix so we can visualize \n",
    "    img = I.numpy()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
